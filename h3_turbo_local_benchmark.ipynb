{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6a2c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import h3\n",
    "import h3_turbo\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import threading\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450719f2",
   "metadata": {},
   "source": [
    "# H3 Turbo Local Benchmark\n",
    "This notebook benchmarks H3 Turbo (GPU) against a vectorized NumPy (CPU) baseline.\n",
    "It runs locally without requiring Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "# Use 10M pings for local execution to fit in standard RAM.\n",
    "# Increase to 50M or 100M if you have >32GB RAM.\n",
    "N_PINGS = int(os.environ.get(\"H3_NUM_PINGS\", 10_000_000))\n",
    "N_ZONES = 100_000\n",
    "RES_RAW = 9\n",
    "RES_JOIN = 7\n",
    "\n",
    "print(f\"Benchmark Configuration:\")\n",
    "print(f\"  Pings: {N_PINGS:,}\")\n",
    "print(f\"  Zones: {N_ZONES:,}\")\n",
    "\n",
    "# Set License\n",
    "if \"H3_TURBO_LICENSE\" in os.environ:\n",
    "    h3_turbo.set_license_key(os.environ[\"H3_TURBO_LICENSE\"])\n",
    "else:\n",
    "    print(\"WARNING: H3_TURBO_LICENSE not set. Benchmarks may fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32510eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- System Information ---\n",
    "import subprocess\n",
    "\n",
    "def get_gpu_name():\n",
    "    \"\"\"Gets the GPU name using nvidia-smi.\"\"\"\n",
    "    try:\n",
    "        # Execute nvidia-smi to get the GPU name\n",
    "        result = subprocess.run(\n",
    "            ['nvidia-smi', '--query-gpu=gpu_name', '--format=csv,noheader'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=True\n",
    "        )\n",
    "        return result.stdout.strip()\n",
    "    except (FileNotFoundError, subprocess.CalledProcessError) as e:\n",
    "        print(f\"Could not get GPU name via nvidia-smi: {e}\")\n",
    "        return \"Unknown_GPU\"\n",
    "\n",
    "gpu_name = get_gpu_name()\n",
    "print(f\"Detected GPU: {gpu_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Generation ---\n",
    "print(\"Generating Data...\")\n",
    "base_index = 0x8928308280fffff\n",
    "k = 200\n",
    "# Generate valid H3 indices using k-ring\n",
    "pool = [h3.str_to_int(x) for x in h3.grid_disk(h3.int_to_str(base_index), k)]\n",
    "pool_np = np.array(pool, dtype=np.uint64)\n",
    "\n",
    "# Sample zones and pings\n",
    "zones_np = np.random.choice(pool_np, N_ZONES, replace=(len(pool_np) < N_ZONES))\n",
    "pings_np = pool_np[np.random.randint(0, len(pool_np), size=N_PINGS)]\n",
    "print(\"Data Generation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8673ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper: CPU Scramble Logic ---\n",
    "def numpy_apply_weight(h3_array):\n",
    "    \"\"\"Vectorized CPU implementation of the scramble logic.\"\"\"\n",
    "    p = h3_array.astype(np.uint64)\n",
    "    c1 = np.uint64(0xBF58476D1CE4E5B9)\n",
    "    c2 = np.uint64(0x94D049BB133111EB)\n",
    "    for _ in range(50):\n",
    "        p ^= (p >> np.uint64(7)); p *= c1\n",
    "        p ^= (p >> np.uint64(13)); p *= c2\n",
    "        p ^= (p >> np.uint64(31))\n",
    "    return p\n",
    "\n",
    "def cpu_task_raw(chunk, res):\n",
    "    parents = [h3.str_to_int(h3.cell_to_parent(h3.int_to_str(h), res)) for h in chunk]\n",
    "    return numpy_apply_weight(np.array(parents, dtype=np.uint64))\n",
    "\n",
    "def cpu_task_join(chunk, res, zone_set):\n",
    "    parents = [h3.str_to_int(h3.cell_to_parent(h3.int_to_str(h), res)) for h in chunk]\n",
    "    parents = numpy_apply_weight(np.array(parents, dtype=np.uint64))\n",
    "    # Note: zone_set lookup is fast, but doing it in parallel helps\n",
    "    return np.array([1 if p in zone_set else 0 for p in parents], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resource Monitoring ---\n",
    "class ResourceMonitor:\n",
    "    def __init__(self, interval=0.1):\n",
    "        self.interval = interval\n",
    "        self.running = False\n",
    "        self.timestamps = []\n",
    "        self.cpu_usage = []\n",
    "        self.ram_usage = []\n",
    "        self.thread = None\n",
    "        self.start_time = None\n",
    "\n",
    "    def _monitor(self):\n",
    "        psutil.cpu_percent(interval=None) # Prime the CPU counter\n",
    "        while self.running:\n",
    "            self.timestamps.append(time.time() - self.start_time)\n",
    "            self.cpu_usage.append(psutil.cpu_percent(interval=None))\n",
    "            self.ram_usage.append(psutil.virtual_memory().percent)\n",
    "            time.sleep(self.interval)\n",
    "\n",
    "    def start(self):\n",
    "        self.running = True\n",
    "        self.start_time = time.time()\n",
    "        self.thread = threading.Thread(target=self._monitor, daemon=True)\n",
    "        self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if self.thread:\n",
    "            self.thread.join()\n",
    "\n",
    "print(\"\\n--- Starting Resource Monitor ---\")\n",
    "monitor = ResourceMonitor(interval=0.2)\n",
    "monitor.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f115b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Benchmark 1: Raw Compute (Transform) ---\n",
    "print(\"\\n--- Benchmark 1: Raw Compute (Transform) ---\")\n",
    "\n",
    "# GPU\n",
    "print(\"Running GPU...\")\n",
    "h3_turbo.warmup()\n",
    "start_gpu = time.time()\n",
    "gpu_raw_results = h3_turbo.batch_transform(pings_np.copy(), RES_RAW)\n",
    "raw_gpu_time = time.time() - start_gpu\n",
    "print(f\"GPU Time: {raw_gpu_time:.4f} s\")\n",
    "\n",
    "# CPU\n",
    "print(\"Running CPU (Multiprocessing)...\")\n",
    "start_cpu = time.time()\n",
    "num_workers = os.cpu_count()\n",
    "chunk_size = (len(pings_np) + num_workers - 1) // num_workers\n",
    "chunks = [pings_np[i:i + chunk_size] for i in range(0, len(pings_np), chunk_size)]\n",
    "\n",
    "with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "    results = pool.starmap(cpu_task_raw, [(c, RES_RAW) for c in chunks])\n",
    "\n",
    "cpu_raw_results = np.concatenate(results)\n",
    "raw_cpu_time = time.time() - start_cpu\n",
    "print(f\"CPU Time: {raw_cpu_time:.4f} s\")\n",
    "print(f\"Speedup: {raw_cpu_time / raw_gpu_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Benchmark 2: Spatial Join ---\n",
    "print(\"\\n--- Benchmark 2: Spatial Join ---\")\n",
    "\n",
    "# GPU\n",
    "print(\"Running GPU...\")\n",
    "start_gpu = time.time()\n",
    "gpu_join_results = h3_turbo.spatial_join(pings_np, zones_np, RES_JOIN)\n",
    "join_gpu_time = time.time() - start_gpu\n",
    "matches_gpu = np.sum(gpu_join_results)\n",
    "print(f\"GPU Time: {join_gpu_time:.4f} s (Matches: {matches_gpu})\")\n",
    "\n",
    "# CPU\n",
    "print(\"Running CPU (Set Lookup)...\")\n",
    "# Pre-calculate zone set (fair comparison)\n",
    "zone_parents = numpy_apply_weight(np.array([h3.str_to_int(h3.cell_to_parent(h3.int_to_str(int(z)), RES_JOIN)) for z in zones_np], dtype=np.uint64))\n",
    "zone_set = set(zone_parents)\n",
    "\n",
    "start_cpu = time.time()\n",
    "num_workers = os.cpu_count()\n",
    "chunk_size = (len(pings_np) + num_workers - 1) // num_workers\n",
    "chunks = [pings_np[i:i + chunk_size] for i in range(0, len(pings_np), chunk_size)]\n",
    "\n",
    "with multiprocessing.Pool(processes=num_workers) as pool:\n",
    "    results = pool.starmap(cpu_task_join, [(c, RES_JOIN, zone_set) for c in chunks])\n",
    "\n",
    "cpu_join_results = np.concatenate(results)\n",
    "join_cpu_time = time.time() - start_cpu\n",
    "matches_cpu = np.sum(cpu_join_results)\n",
    "print(f\"CPU Time: {join_cpu_time:.4f} s (Matches: {matches_cpu})\")\n",
    "print(f\"Speedup: {join_cpu_time / join_gpu_time:.2f}x\")\n",
    "\n",
    "monitor.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a0738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization ---\n",
    "print(\"\\n--- Generating Plots ---\")\n",
    "\n",
    "# 1. Performance Comparison\n",
    "tasks = ['Raw Transform', 'Spatial Join']\n",
    "cpu_times = [raw_cpu_time, join_cpu_time]\n",
    "gpu_times = [raw_gpu_time, join_gpu_time]\n",
    "\n",
    "x = np.arange(len(tasks))\n",
    "width = 0.35\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(f\"H3 Turbo Benchmark on {gpu_name}\", fontsize=16)\n",
    "\n",
    "# Plot 1: Execution Time\n",
    "rects1 = ax1.bar(x - width/2, cpu_times, width, label='NumPy (CPU)', color='#FF9999')\n",
    "rects2 = ax1.bar(x + width/2, gpu_times, width, label='H3 Turbo (GPU)', color='#66B2FF')\n",
    "\n",
    "ax1.set_ylabel('Time (seconds) - Log Scale')\n",
    "ax1.set_title('Execution Time (Lower is Better)')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(tasks)\n",
    "ax1.legend()\n",
    "ax1.set_yscale('log')\n",
    "ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "\n",
    "# Plot 2: Speedup Factor\n",
    "speedups = [c / g for c, g in zip(cpu_times, gpu_times)]\n",
    "bars = ax2.bar(tasks, speedups, color='green', alpha=0.7)\n",
    "ax2.set_ylabel('Speedup Factor (X times faster)')\n",
    "ax2.set_title('GPU Acceleration Factor')\n",
    "ax2.bar_label(bars, fmt='%.1fx', padding=3)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust for suptitle\n",
    "\n",
    "# Sanitize GPU name for filename\n",
    "gpu_name_sanitized = \"\".join(c for c in gpu_name if c.isalnum() or c in (' ', '_')).rstrip().replace(' ', '_')\n",
    "perf_filename = f'local_benchmark_performance_{gpu_name_sanitized}.png'\n",
    "plt.savefig(perf_filename)\n",
    "print(f\"Saved performance plot to {perf_filename}\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Spatial Distribution Sample\n",
    "sample_size = 10_000\n",
    "print(f\"Plotting spatial sample of {sample_size} points...\")\n",
    "\n",
    "pings_sample = np.random.choice(pings_np, sample_size, replace=False)\n",
    "zones_sample = np.random.choice(zones_np, sample_size, replace=False)\n",
    "\n",
    "# Convert H3 to Lat/Lon for plotting\n",
    "pings_coords = np.array([h3.cell_to_latlng(h3.int_to_str(h)) for h in pings_sample])\n",
    "zones_coords = np.array([h3.cell_to_latlng(h3.int_to_str(h)) for h in zones_sample])\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(pings_coords[:, 1], pings_coords[:, 0], c='blue', alpha=0.1, s=1, label='Pings')\n",
    "plt.scatter(zones_coords[:, 1], zones_coords[:, 0], c='red', alpha=0.5, s=5, label='Hot Zones')\n",
    "plt.title(f'Spatial Distribution (Sample of {sample_size}) on {gpu_name}')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.legend()\n",
    "\n",
    "spatial_filename = f'local_spatial_distribution_{gpu_name_sanitized}.png'\n",
    "plt.savefig(spatial_filename)\n",
    "print(f\"Saved spatial plot to {spatial_filename}\")\n",
    "plt.show()\n",
    "\n",
    "# 3. Resource Usage\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(monitor.timestamps, monitor.cpu_usage, label='CPU Usage (%)', color='orange')\n",
    "plt.plot(monitor.timestamps, monitor.ram_usage, label='RAM Usage (%)', color='purple')\n",
    "plt.title(f'System Resource Usage during Benchmark on {gpu_name}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Usage (%)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "resource_filename = f'local_resource_usage_{gpu_name_sanitized}.png'\n",
    "plt.savefig(resource_filename)\n",
    "print(f\"Saved resource usage plot to {resource_filename}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
